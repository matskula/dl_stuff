{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_gradient\n",
    "from metrics import multiclass_accuracy \n",
    "import linear_classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def prepare_for_linear_classifier(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    # Add another channel with ones as a bias term\n",
    "    train_flat_with_ones = np.hstack([train_flat, np.ones((train_X.shape[0], 1))])\n",
    "    test_flat_with_ones = np.hstack([test_flat, np.ones((test_X.shape[0], 1))])    \n",
    "    return train_flat_with_ones, test_flat_with_ones\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_linear_classifier(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Gradient check passed!\nGradient check passed!\nGradient check passed!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "\n",
    "def square(x):\n",
    "    assert x.shape == (1,), x.shape\n",
    "    return float(x*x), 2*x\n",
    "\n",
    "check_gradient(square, np.array([3.0]))\n",
    "\n",
    "def array_sum(x):\n",
    "    assert x.shape == (2,), x.shape\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_sum, np.array([3.0, 2.0]))\n",
    "\n",
    "def array_2d_sum(x):\n",
    "    assert x.shape == (2,2)\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_2d_sum, np.array([[3.0, 2.0], [1.0, 0.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "probs = linear_classifer.softmax(np.array([1000, 0, 0]))\n",
    "assert np.isclose(probs[0], 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "5.006760443547122"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "probs = linear_classifer.softmax(np.array([-5, 0, 5]))\n",
    "linear_classifer.cross_entropy_loss(probs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Gradient check passed!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "loss, grad = linear_classifer.softmax_with_cross_entropy(np.array([1, 0, 0]), 1)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, 1), np.array([1, 0, 0], np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Gradient check passed!\nGradient check passed!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "# Test batch_size = 1\n",
    "num_classes = 4\n",
    "batch_size = 1\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
    "target_index = np.random.randint(0, num_classes, size=batch_size).astype(np.int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Test batch_size = 3\n",
    "num_classes = 4\n",
    "batch_size = 3\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
    "target_index = np.random.randint(0, num_classes, size=batch_size).astype(np.int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Make sure maximum subtraction for numberic stability is done separately for every sample in the batch\n",
    "probs = linear_classifer.softmax(np.array([[20,0,0], [1000, 0, 0]]))\n",
    "assert np.all(np.isclose(probs[:, 0], 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Gradient check passed!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_classes = 2\n",
    "num_features = 3\n",
    "np.random.seed(42)\n",
    "W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(np.float)\n",
    "X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(np.float)\n",
    "target_index = np.ones(batch_size, dtype=np.int)\n",
    "\n",
    "loss, dW = linear_classifer.linear_softmax(X, W, target_index)\n",
    "check_gradient(lambda w: linear_classifer.linear_softmax(X, w, target_index), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Gradient check passed!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "# TODO Implement l2_regularization function that implements loss for L2 regularization\n",
    "linear_classifer.l2_regularization(W, 0.01)\n",
    "check_gradient(lambda w: linear_classifer.l2_regularization(w, 0.01), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch 0, loss: 2.301968\n",
      "Epoch 1, loss: 2.301446\n",
      "Epoch 2, loss: 2.301173\n",
      "Epoch 3, loss: 2.301028\n",
      "Epoch 4, loss: 2.300950\n",
      "Epoch 5, loss: 2.300909\n",
      "Epoch 6, loss: 2.300886\n",
      "Epoch 7, loss: 2.300874\n",
      "Epoch 8, loss: 2.300868\n",
      "Epoch 9, loss: 2.300864\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "loss_history = classifier.fit(train_X, train_y, epochs=10, learning_rate=1e-3, batch_size=300, reg=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show = plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy on v set:  0.251\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy on v set: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch 0, loss: 8.493746\n",
      "Epoch 1, loss: 7.686627\n",
      "Epoch 2, loss: 7.419016\n",
      "Epoch 3, loss: 5.812184\n",
      "Epoch 4, loss: 6.828660\n",
      "Epoch 5, loss: 7.205606\n",
      "Epoch 6, loss: 8.909157\n",
      "Epoch 7, loss: 11.121701\n",
      "Epoch 8, loss: 7.670254\n",
      "Epoch 9, loss: 6.430701\nAccuracy after training for 100 epochs:  0.168\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Now, let's train more and see if it performs better\n",
    "classifier.fit(train_X, train_y, epochs=100, learning_rate=1e-1, batch_size=128, reg=1e-3)\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy after training for 100 epochs: \", accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing best hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 256\n",
    "\n",
    "learning_rates = [1e-1, 1e-2, 1e-3, 1e-4]\n",
    "reg_strengths = [1e-3, 1e-4, 1e-5, 1e-6]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "for i in learning_rates:\n",
    "    for j in reg_strengths:\n",
    "        lc = linear_classifer.LinearSoftmaxClassifier()\n",
    "        lc.fit(train_X, train_y, epochs=num_epochs, learning_rate=i, batch_size=batch_size, reg=j)\n",
    "        pred = lc.predict(val_X)\n",
    "        accuracy = multiclass_accuracy(pred, val_y)\n",
    "        print('lr: %f | rs: %f | res: %f' % (i, j, accuracy))\n",
    "        if accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = accuracy\n",
    "            best_classifier = lc\n",
    "            \n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Linear soft-max classifier test set accuracy: 0.216000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Linear soft-max classifier test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}